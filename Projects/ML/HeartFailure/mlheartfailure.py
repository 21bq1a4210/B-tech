# -*- coding: utf-8 -*-
"""MLHeartFailure.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1djgegE11dtUgzmcZC2r7k5aJfrfFKij_

#HeartFailure through DecisionTree
"""

# Import necessary libraries
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
import os
from graphviz import Source

# Load the dataset
data = pd.read_csv('/content/sample_data/heart.csv')

# Split the data into features (X) and target variable (y)
X = data.drop('HeartDisease', axis=1)
y = data['HeartDisease']

# Convert categorical variables to dummy/indicator variables
X = pd.get_dummies(X, columns=['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope'])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the parameter grid to search
param_grid = {
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10, 20],  # Adjusted values
    'min_samples_leaf': [1, 2, 4]
}

# Create a decision tree classifier
base_clf = DecisionTreeClassifier(random_state=42)

# Use GridSearchCV to search for the best hyperparameters
grid_search = GridSearchCV(base_clf, param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train, y_train)

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Use the best model for predictions
best_clf = grid_search.best_estimator_

# Predict the response for the test dataset
y_pred = best_clf.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

# Print the results
print(f'Accuracy: {accuracy:.2f}')
print('Confusion Matrix:')
print(conf_matrix)
print('Classification Report:')
print(classification_rep)

# Where to save the figures
PROJECT_ROOT_DIR = "."
def image_path(fig_id):
    return os.path.join(PROJECT_ROOT_DIR, "sample_data", fig_id)

# Export the decision tree to a dot file
export_graphviz(
    best_clf,
    out_file=image_path("heart_failure_tree.dot"),
    feature_names=X.columns,
    class_names=['Normal', 'Heart Disease'],
    rounded=True,
    filled=True
)

# Visualize the decision tree using graphviz
Source.from_file("./sample_data/heart_failure_tree.dot").view()

"""#Testing:

##Testing sample1
"""

#Using above model- sample1(head)
sample1 = pd.concat([X.head(), y.head()], axis=1)
sample1['Prediction(HeartDisease)'] = clf.predict(X.head()).round(2)
sample1['Error'] = sample1['HeartDisease'] - sample1['Prediction(HeartDisease)']
print(sample1)
print(np.mean(sample1['Error']))

"""##Testion sample2"""

#Using above model- sample2(tail)
sample2 = pd.concat([X.tail(), y.tail()], axis=1)
sample2['Prediction(HeartDisease)'] = clf.predict(X.tail()).round(2)
sample2['Error'] = sample2['HeartDisease'] - sample2['Prediction(HeartDisease)']
print(sample2)
print(np.mean(sample2['Error']))